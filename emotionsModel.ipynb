{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writen by Horia-Gabriel Radu - 2021-2022\n",
    "# for Third Year Project at University of Manchester\n",
    "#\n",
    "#  Used dataset basic for emotion detection model training from:\n",
    "#   Reliable crowdsourcing and deep locality-preserving learning for expression recognition in the wild,\n",
    "#   Li, Shan and Deng, Weihong and Du, JunPing,\n",
    "#   Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on,\n",
    "#   2584--2593,\n",
    "#   2017,\n",
    "#   IEEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "#import object_detection\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers\n",
    "import functools\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ea2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de761e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_color(image, brightness=0, contrast=0, saturation=0, hue=0):\n",
    "    transformations = []\n",
    "    if brightness > 0:\n",
    "        transformations.append(functools.partial(tf.image.random_brightness, max_delta=brightness))\n",
    "    if contrast > 0:\n",
    "        transformations.append(functools.partial(tf.image.random_contrast, lower=max(0, 1 - contrast), upper=1 + contrast))\n",
    "    if saturation > 0:\n",
    "        transformations.append(functools.partial(tf.image.random_saturation, lower=max(0, 1 - saturation), upper=1 + saturation))\n",
    "    if hue > 0:\n",
    "        transformations.append(functools.partial(tf.image.random_hue, max_delta=hue))\n",
    "\n",
    "    random.shuffle(transformations)\n",
    "    for transformation in transformations:\n",
    "        image = transformation(image)\n",
    "\n",
    "    return image \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!pip list\n",
    "# #!pip install --upgrade tensorflow_hub\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess= tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df403b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data - basic/basic/AllFaces/aligned/\"\n",
    "LABELS = \"data - basic/basic/EmoLabel/list_patition_label.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {0:\"Surprise\", 1:\"Fear\", 2:\"Disgust\", 3:\"Happiness\", 4:\"Sadness\", 5:\"Anger\", 6:\"Neutral\"}\n",
    "labels_list = [{'name':'Surprise', 'id':0}, {'name':'Fear', 'id':1}, {'name':'Disgust', 'id':2}, {'name':'Happiness', 'id':3}, {'name':'Sadness', 'id':4}, {'name':'Anger', 'id':5}, {'name':'Neutral', 'id':6}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_labels = []\n",
    "tfdata = []\n",
    "tflabels = []\n",
    "sets = []\n",
    "\n",
    "with open(LABELS, 'r') as f:\n",
    "    for l in f.readlines():\n",
    "        words = l.split()\n",
    "        file_labels.append((words[0], words[1]))\n",
    "\n",
    "#random.shuffle(file_labels)\n",
    "\n",
    "for x in file_labels:\n",
    "    file_contents = tf.io.read_file(DATA_PATH + x[0][:-4] + \"_aligned.jpg\")\n",
    "    #dataset.append({'image':tf.io.decode_jpeg(file_contents), 'label':int(x[1])})\n",
    "    image = tf.io.decode_jpeg(file_contents)\n",
    "    rev = tf.reverse(image, [1])\n",
    "#     tfdata.append(tf.io.decode_jpeg(file_contents))\n",
    "#     tflabels.append(int(x[1]) - 1)\n",
    "#     tfdata.append(rev)\n",
    "#     tflabels.append(int(x[1]) - 1)\n",
    "    sets.append((image, int(x[1]) - 1))\n",
    "    sets.append((rev, int(x[1]) - 1))\n",
    "\n",
    "random.shuffle(sets)\n",
    "    \n",
    "for t in sets:\n",
    "    #image = tf.image.central_crop(t[0], 0.90)\n",
    "    image = cv2.resize(t[0].numpy(), (50, 50))\n",
    "    image = cv2.resize(image, (100, 100))\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    tfdata.append(augmentation_color(image, 0.25, 0.2, 0.2, 0.1))\n",
    "    tflabels.append(t[1])\n",
    "    \n",
    "print(len(tfdata))\n",
    "print(len(tflabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd8490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = tfds.features.FeaturesDict({\n",
    "#     'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
    "#     'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=7),\n",
    "# })\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tfdata, tflabels))\n",
    "print(len(dataset))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e8eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.shuffle(buffer_size=len(dataset))\n",
    "print(len(dataset))\n",
    "\n",
    "train_size = int(0.85 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "#test_size = int(0.15 * len(dataset))\n",
    "print(train_size)\n",
    "#print(test_size)\n",
    "print(val_size)\n",
    "\n",
    "\n",
    "# # dataset = dataset.shuffle(1000)\n",
    "# train_dataset = dataset.take(train_size)\n",
    "# test_dataset = dataset.skip(train_size)\n",
    "# val_dataset = test_dataset.skip(test_size)\n",
    "# test_dataset = test_dataset.take(test_size)\n",
    "\n",
    "# dataset = dataset.shuffle(1000)\n",
    "train_dataset = dataset.take(train_size)\n",
    "#test_dataset = dataset.skip(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "val_dataset = dataset.take(val_size)\n",
    "test_dataset = val_dataset\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9013ebf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(len(train_dataset)//2).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_dataset.shuffle(len(val_dataset)//2).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "#DATASET DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293bf2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "for i in range(9):\n",
    "    for im,la in train_dataset.take(1):\n",
    "#         train_dataset = train_dataset.skip(1)\n",
    "        im = im/255\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(im[0])\n",
    "        plt.title( \"Class_label: \" + str(labels_dict[la[0].numpy()]))\n",
    "        plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331abfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorboard_callback(directory, name):\n",
    "    log_dir = directory + \"/\" + name\n",
    "    t_c = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
    "    return t_c\n",
    "\n",
    "def model_checkpoint(directory, name):\n",
    "    log_dir = directory + \"/\" + name\n",
    "    m_c = tf.keras.callbacks.ModelCheckpoint(filepath=log_dir,\n",
    "                                             monitor=\"val_accuracy\",\n",
    "                                             save_best_only=True,\n",
    "                                             save_weights_only=True,\n",
    "                                             verbose=1)\n",
    "    return m_c\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch == 20:\n",
    "        return lr * 0.1\n",
    "    if epoch == 40:\n",
    "        return lr * 0.1\n",
    "    else:\n",
    "        return lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c27ca",
   "metadata": {},
   "source": [
    "# -- OPTION 1 -- EFFICIENTNET --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797cdd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions on using tensorflow for machine learning from (Accessed 10 March 2022):\n",
    "# https://towardsdatascience.com/image-classification-transfer-learning-and-fine-tuning-using-tensorflow-a791baf9dbf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47485cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_efficientnet = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False)\n",
    "base_model_efficientnet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c0e7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape = (100,100,3), name='inputLayer')\n",
    "x = base_model_efficientnet(inputs, training = False)\n",
    "x = layers.GlobalAveragePooling2D(name='poolingLayer')(x)\n",
    "x = layers.Dense(7, name='outputLayer')(x)\n",
    "outputs = layers.Activation(activation=\"softmax\", dtype=tf.float32, name='activationLayer')(x)\n",
    "\n",
    "model_efficientnet = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e08de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_efficientnet.trainable = True\n",
    "# model_efficientnet.trainable = True\n",
    "for layer in model_efficientnet.layers[1].layers:\n",
    "    if isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234acc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_efficientnet.summary()\n",
    "for lnum, layer in enumerate(base_model_efficientnet.layers):\n",
    "    print(lnum, layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2450ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_efficientnet.summary()\n",
    "for lnum, layer in enumerate(model_efficientnet.layers):\n",
    "    print(lnum, layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be545e3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "model_efficientnet.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer = tfa.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-4),\n",
    "              metrics = [\"accuracy\"])\n",
    "hist_model = model_efficientnet.fit(train_dataset,\n",
    "                             epochs=50,\n",
    "                             steps_per_epoch=len(train_dataset),\n",
    "                             validation_data=val_dataset,\n",
    "                             validation_steps=int(0.1*len(val_dataset)),\n",
    "                             callbacks=[tensorboard_callback(\"Tensorboard_E\", \"model_tuned\"), model_checkpoint(\"Checkpoints_E\", \"model_tuned.ckpt\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd1f03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_efficientnet.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed858299",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "preds = model_efficientnet.predict(test_dataset, verbose = 1)\n",
    "pred_labels = tf.argmax(preds, axis=1)\n",
    "test_labels = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "\n",
    "# Step 1\n",
    "test_image_batches = []\n",
    "for images, labels in test_dataset.take(-1):\n",
    "    test_image_batches.append(images.numpy())\n",
    "\n",
    "# Step 2\n",
    "test_images = [item for sublist in test_image_batches for item in sublist]\n",
    "\n",
    "plt.figure(figsize = (20,20))\n",
    "for i in range(9):\n",
    "    random_int_index = random.choice(range(len(test_images)))\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_images[random_int_index]/255.)\n",
    "    if test_labels[random_int_index] == pred_labels[random_int_index]:\n",
    "        color = \"g\"\n",
    "    else:\n",
    "        color = \"r\"\n",
    "    plt.title(\"True Label: \" + str(labels_dict[test_labels[random_int_index]]) + \" || \" + \"Predicted Label: \" +\n",
    "              str(labels_dict[pred_labels[random_int_index].numpy()]) + \"\\n\" + \n",
    "              str(np.asarray(tf.reduce_max(preds, axis = 1))[random_int_index]), c=color)\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a278846",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(model_efficientnet, \"saved_models/model_efficient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46764a51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2# Get keras model\n",
    "# # model = ...# Convert Keras model to ConcreteFunction    \n",
    "# full_model = tf.function(lambda inputs: model_efficientnet(inputs))    \n",
    "# full_model = full_model.get_concrete_function([tf.TensorSpec(model_input.shape, model_input.dtype) for model_input in model_efficientnet.inputs])# Get frozen ConcreteFunction    \n",
    "# frozen_func = convert_variables_to_constants_v2(full_model)\n",
    "# frozen_func.graph.as_graph_def()# Save frozen graph from frozen ConcreteFunction to hard drive\n",
    "# tf.io.write_graph(graph_or_graph_def=frozen_func.graph,logdir=\"./frozen_models\",name=\"frozen_efficient.pb\",as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4515d6f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# lista = [n.name for n in graph_def.node]\n",
    "# print(lista[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac387ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "loaded = tf.saved_model.load('saved_models/model_efficient')\n",
    "infer = loaded.signatures['serving_default']\n",
    "\n",
    "f = tf.function(infer).get_concrete_function(inputLayer=tf.TensorSpec(shape=[None, 100, 100, 3], dtype=tf.float32))\n",
    "f2 = convert_variables_to_constants_v2(f)\n",
    "graph_def = f2.graph.as_graph_def()\n",
    "\n",
    "for i in reversed(range(len(graph_def.node))):\n",
    "    #print(graph_def.node[i].op)\n",
    "    if graph_def.node[i].op == 'NoOp':\n",
    "        del graph_def.node[i]\n",
    "\n",
    "for node in graph_def.node:\n",
    "    for i in reversed(range(len(node.input))):\n",
    "        if node.input[i][0] == '^':\n",
    "            del node.input[i]\n",
    "            \n",
    "\n",
    "\n",
    "graph_def = optimize_for_inference_lib.optimize_for_inference(graph_def,\n",
    "                                                              ['inputLayer'],\n",
    "                                                              ['StatefulPartitionedCall/StatefulPartitionedCall/EfficientNet/activationLayer/Softmax'],\n",
    "                                                              tf.float32.as_datatype_enum)\n",
    "\n",
    "with tf.io.gfile.GFile('frozen_models/frozen_graph_efficient.pb', 'wb') as f:\n",
    "    f.write(graph_def.SerializeToString())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n",
    "# cv2.dnn.writeTextGraph(\"frozen_models/frozen_efficient.pb\", \"frozen_models/frozen_efficient.pbtxt\")\n",
    "cv2.dnn.writeTextGraph(\"frozen_models/frozen_graph_efficient.pb\", \"frozen_models/frozen_graph_efficient.pbtxt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0948e112",
   "metadata": {},
   "source": [
    "# -- OPTION 2 -- RESNET --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d54481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_resnet = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v2_50/classification/5\",\n",
    "                   trainable=True, arguments=dict(batch_norm_momentum=0.997))\n",
    "\n",
    "])\n",
    "base_model_resnet.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec540d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape = ([100,100,3]), name='inputLayer')\n",
    "x = base_model_resnet(inputs, training = False)\n",
    "# x = layers.BatchNormalization(name='poolingLayer')(x)\n",
    "x = layers.Dense(7, name='outputLayer')(x)\n",
    "outputs = layers.Activation(activation=\"softmax\", dtype=tf.float32, name='activationLayer')(x)\n",
    "\n",
    "model_resnet = tf.keras.Model(inputs, outputs, name=\"ResNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de71fe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model_resnet.trainable = True\n",
    "# model_resnet.trainable = True\n",
    "for layer in model_resnet.layers[1].layers:\n",
    "    if isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9461b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_resnet.summary()\n",
    "for lnum, layer in enumerate(base_model_resnet.layers):\n",
    "    print(lnum, layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4509b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet.summary()\n",
    "for lnum, layer in enumerate(model_resnet.layers):\n",
    "    print(lnum, layer.name, layer.trainable, layer.dtype, layer.dtype_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6621c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available GPUs: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be73e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "model_resnet.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer = tfa.optimizers.AdamW(learning_rate=1e-4, weight_decay=1e-4),\n",
    "              metrics = [\"accuracy\"])\n",
    "hist_model_tuned = model_resnet.fit(train_dataset,\n",
    "                             epochs=20,\n",
    "                             steps_per_epoch=len(train_dataset),\n",
    "                             validation_data=val_dataset,\n",
    "                             validation_steps=int(0.1*len(val_dataset)),\n",
    "                             \n",
    "                             callbacks=[tensorboard_callback(\"Tensorboard_R\", \"model_tuned\"), model_checkpoint(\"Checkpoints_R\", \"model_tuned.ckpt\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d397f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = model_resnet.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80755506",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model_resnet.predict(test_dataset, verbose = 1)\n",
    "pred_labels = tf.argmax(preds, axis=1)\n",
    "test_labels = np.concatenate([y for x, y in test_dataset], axis=0)\n",
    "\n",
    "# Step 1\n",
    "test_image_batches = []\n",
    "for images, labels in test_dataset.take(-1):\n",
    "    test_image_batches.append(images.numpy())\n",
    "\n",
    "# Step 2\n",
    "test_images = [item for sublist in test_image_batches for item in sublist]\n",
    "len(test_images)\n",
    "plt.figure(figsize = (20,20))\n",
    "for i in range(9):\n",
    "    random_int_index = random.choice(range(len(test_images)))\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_images[random_int_index]/255.)\n",
    "    if test_labels[random_int_index] == pred_labels[random_int_index]:\n",
    "        color = \"g\"\n",
    "    else:\n",
    "        color = \"r\"\n",
    "    plt.title(\"True Label: \" + str(labels_dict[test_labels[random_int_index]]) + \" || \" + \"Predicted Label: \" +\n",
    "              str(labels_dict[pred_labels[random_int_index].numpy()]) + \"\\n\" + \n",
    "              str(np.asarray(tf.reduce_max(preds, axis = 1))[random_int_index]), c=color)\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf447776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_resnet.save(\"saved_models/model_resnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e68e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75474dea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "loaded = tf.saved_model.load('saved_models/model_resnet')\n",
    "infer = loaded.signatures['serving_default']\n",
    "\n",
    "f = tf.function(infer).get_concrete_function(inputLayer=tf.TensorSpec(shape=[None, 100, 100, 3], dtype=tf.float32))\n",
    "f2 = convert_variables_to_constants_v2(f)\n",
    "graph_def = f2.graph.as_graph_def()\n",
    "\n",
    "for i in reversed(range(len(graph_def.node))):\n",
    "    #print(graph_def.node[i].op)\n",
    "    if graph_def.node[i].op == 'NoOp':\n",
    "        del graph_def.node[i]\n",
    "\n",
    "for node in graph_def.node:\n",
    "    for i in reversed(range(len(node.input))):\n",
    "        if node.input[i][0] == '^':\n",
    "            del node.input[i]\n",
    "            \n",
    "\n",
    "\n",
    "graph_def = optimize_for_inference_lib.optimize_for_inference(graph_def,\n",
    "                                                              ['inputLayer'],\n",
    "                                                              ['StatefulPartitionedCall/StatefulPartitionedCall/ResNet/activationLayer/Softmax'],\n",
    "                                                              tf.float32.as_datatype_enum)\n",
    "\n",
    "with tf.io.gfile.GFile('frozen_models/frozen_graph_resnet.pb', 'wb') as f:\n",
    "    f.write(graph_def.SerializeToString())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a5879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n",
    "# cv2.dnn.writeTextGraph(\"frozen_models/frozen_efficient.pb\", \"frozen_models/frozen_efficient.pbtxt\")\n",
    "cv2.dnn.writeTextGraph(\"frozen_models/frozen_graph_resnet.pb\", \"frozen_models/frozen_graph_resnet.pbtxt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b0932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3727eb9",
   "metadata": {},
   "source": [
    "# _________________ TESTING _________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f8a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecacb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "caffeWeightFile = \"../detectFace/models/res10_300x300_ssd_iter_140000_fp16.caffemodel\";\n",
    "caffeConfigFile = \"../detectFace/models/deploy.prototxt\";\n",
    "tensorflowWeightFile = \"../detectFace/models/opencv_face_detector_uint8.pb\";\n",
    "tensorflowConfigFile = \"../detectFace/models/opencv_face_detector.pbtxt\";\n",
    "netFace = cv2.dnn.readNetFromTensorflow(tensorflowWeightFile, tensorflowConfigFile);\n",
    "\n",
    "netEmotion = cv2.dnn.readNet(\"frozen_models/frozen_graph_resnet.pb\")\n",
    "labels_dict = {0:\"Surprise\", 1:\"Fear\", 2:\"Disgust\", 3:\"Happiness\", 4:\"Sadness\", 5:\"Anger\", 6:\"Neutral\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09842ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"test\")\n",
    "\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "    frame = np.flip(frame, 1)\n",
    "    if not ret:\n",
    "        print(\"failed to grab frame\")\n",
    "        break\n",
    "        \n",
    "    frameCopy = frame.copy()\n",
    "    faces = []\n",
    "    \n",
    "    (h, w) = frame.shape[:2]\n",
    "    inputBlob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0));\n",
    "    \n",
    "    netFace.setInput(inputBlob, \"data\");\n",
    "    detections = netFace.forward(\"detection_out\");\n",
    "\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.7:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            text = \"{:.2f}%\".format(confidence * 100)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            #cv2.rectangle(frameCopy, (startX, startY), (endX, endY), (0, 0, 255), 2)\n",
    "            #cv2.putText(frameCopy, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "            \n",
    "            faces.append([startX, startY, endX, endY])\n",
    "            \n",
    "    for f in faces:\n",
    "        face = frameCopy[f[1]:f[3], f[0]:f[2]]\n",
    "        faceInput = cv2.resize(face, (50, 50))\n",
    "        faceInput = cv2.resize(faceInput, (100, 100))\n",
    "        plt.imshow(faceInput)\n",
    "        emotion = cv2.dnn.blobFromImage(faceInput, 1.0, (100, 100))\n",
    "        netEmotion.setInput(emotion)\n",
    "\n",
    "        outEmotion = netEmotion.forward();\n",
    "        cv2.putText(frameCopy, labels_dict[outEmotion.argmax()], (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "        \n",
    "    cv2.imshow(\"test\", frameCopy)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        img_name = \"opencv_frame_{}.png\".format(img_counter)\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(\"{} written!\".format(img_name))\n",
    "        img_counter += 1\n",
    "        \n",
    "    \n",
    "\n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ba093",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1001\n",
    "test = cv2.resize(face, (100, 100))\n",
    "test = cv2.resize(test, (50, 50))\n",
    "test = cv2.resize(test, (100, 100))\n",
    "#test = tfdata[n].numpy()\n",
    "\n",
    "blb = cv2.dnn.blobFromImage(test, 1.0, (100, 100))\n",
    "\n",
    "plt.imshow(test)\n",
    "\n",
    "netEmotion.setInput(blb)\n",
    "out = netEmotion.forward()\n",
    "\n",
    "#print(\"true label - \" + str(labels_dict[tflabels[n]]) + \" | predicted label - \" + labels_dict[out.argmax()])\n",
    "print(\"predicted label - \" + labels_dict[out.argmax()])\n",
    "#print(\"true label - \" + labels_dict[tflabels[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1e278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"test\")\n",
    "\n",
    "cv2.imshow(\"test\", test)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d0b56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nr = 1010\n",
    "\n",
    "showImg = cv2.resize(tfdata[nr].numpy(), (50, 50))\n",
    "showImg = cv2.resize(showImg, (100, 100))\n",
    "#tfdata[nr] = tf.convert_to_tensor(showImg)\n",
    "# showImg = tf.compat.v1.image.resize(tfdata[0],[43, 43], method=tf.compat.v1.image.ResizeMethod.AREA)\n",
    "# showImg = tf.compat.v1.image.resize(showImg,[86, 86], method=tf.compat.v1.image.ResizeMethod.AREA)\n",
    "plt.imshow(showImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tfdata[nr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7de0021",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nr = 1010\n",
    "plt.imshow(sets[1010][0])\n",
    "print(labels_dict[tflabels[nr]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0173759d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3810jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
